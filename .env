# Local Documents Directory if not be configured, $HOME()/.vivink/documents will be used 
# if configured, will be used only
#LOCAL_DOCS_DIR=

# Vector Store Mode: in-memory OR in-disk
VECTOR_STORE_MODE=in-memory 

# Embedding Model
EMBEDDING_MODEL=BAAI/bge-large-zh-v1.5

# speicified ollama
OLLAMA_MODEL=qwen2.5:3b

# specified local model
HUGGINGFACE_MODEL=Qwen/Qwen2.5-3B-Instruct

# LlamaIndex Custom LLM Model By API
CUSTOMIZED_LLM=deepseek-chat

####################使用兼容OpenAI的API####################
# API URL，配置实际使用的大模型厂商API URL
CUSTOMIZED_LLM_URL=https://api.deepseek.com

# API Key, 实际使用的大模型厂商分配的API KEY
  
# 填写在此处(本地调试用，不推荐)
#CUSTOMIZED_LLM_APIKEY={实际的API KEY}

# 也可在启动应用程序前 设置环境变量，如：
# export CUSTOMIZED_LLM_APIKEY={实际的API KEY}
# python3 app.py